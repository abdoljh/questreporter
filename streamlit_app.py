# ================================================================================
# ACADEMIC REPORT WRITER PRO - VERSION 7.0
# INTEGRATED WITH master_orchestrator (ResearchOrchestrator)
# ================================================================================
# 
# FEATURES:
# ‚úÖ Uses 18 academic search engines via ResearchOrchestrator
# ‚úÖ Real metadata extraction (authors, venues, years) from academic APIs
# ‚úÖ Proper IEEE/APA citations with actual author names
# ‚úÖ Research gap analysis from master_orchestrator
# ‚úÖ No web search - only authoritative academic sources
# ‚úÖ Session-only API keys (safe for public deployment)
#
# EXECUTION: 3-5 minutes | API CALLS: ~20-30 total
# ================================================================================

import streamlit as st
import json
import requests
import time
import os
import sys
from datetime import datetime
from typing import List, Dict, Any, Tuple
import re
from urllib.parse import urlparse
from pathlib import Path

# ================================================================================
# IMPORT master_orchestrator COMPONENTS
# ================================================================================

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from master_orchestrator import ResearchOrchestrator
    ORCHESTRATOR_AVAILABLE = True
except ImportError as e:
    ORCHESTRATOR_AVAILABLE = False
    st.error(f"Failed to import master_orchestrator: {e}")

# Keep the academic API utilities for direct access if needed
try:
    from arxiv_utils import fetch_and_process_arxiv
    ARXIV_AVAILABLE = True
except ImportError:
    ARXIV_AVAILABLE = False

try:
    from pubmed_utils import fetch_and_process_pubmed
    PUBMED_AVAILABLE = True
except ImportError:
    PUBMED_AVAILABLE = False

try:
    from doi_utils import fetch_and_process_doi
    DOI_AVAILABLE = True
except ImportError:
    DOI_AVAILABLE = False

try:
    from s2_utils import fetch_and_process_papers
    S2_AVAILABLE = True
except ImportError:
    S2_AVAILABLE = False

try:
    from openalex_utils import fetch_and_process_openalex
    OPENALEX_AVAILABLE = True
except ImportError:
    OPENALEX_AVAILABLE = False

# ================================================================================
# CONFIGURATION
# ================================================================================

# Model configuration for report generation
MODEL_PRIMARY = "claude-sonnet-4-20250514"
MODEL_FALLBACK = "claude-haiku-3-5-20241022"

# Rate limiting for Anthropic API (more conservative)
MIN_API_DELAY = 3.0  # Increased from 2.0
RETRY_DELAYS = [10, 20, 40]  # More conservative retry delays

# ================================================================================
# STREAMLIT UI SETUP
# ================================================================================

st.set_page_config(
    page_title="Academic Report Writer Pro",
    page_icon="üìù",
    layout="wide"
)

st.markdown("""
<style>
    .stProgress > div > div > div > div { background-color: #4F46E5; }
    .source-item {
        padding: 0.5rem;
        margin: 0.25rem 0;
        background-color: #F0F9FF;
        border-radius: 0.25rem;
        border-left: 3px solid #3B82F6;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border-left: 4px solid #28a745;
        border-radius: 0.3rem;
        margin: 1rem 0;
        font-weight: bold;
        color: #155724;
    }
    .info-box {
        padding: 1rem;
        background-color: #d1ecf1;
        border-left: 4px solid #17a2b8;
        border-radius: 0.3rem;
        margin: 1rem 0;
    }
    .engine-badge {
        display: inline-block;
        padding: 0.25rem 0.5rem;
        margin: 0.25rem;
        background-color: #e3f2fd;
        border-radius: 0.25rem;
        font-size: 0.85em;
        border: 1px solid #90caf9;
    }
    .engine-badge.premium {
        background-color: #fff3e0;
        border-color: #ffcc80;
    }
</style>
""", unsafe_allow_html=True)



# ================================================================================
# UTILITY FUNCTIONS - Safe Type Conversion
# ================================================================================

def safe_int(value, default=0):
    """Safely convert value to int, handling 'N/A', None, strings, etc."""
    if value is None:
        return default
    if isinstance(value, int):
        return value
    if isinstance(value, str):
        # Handle 'N/A', 'unknown', empty strings
        if value.strip().upper() in ('N/A', 'NA', 'UNKNOWN', '', 'NONE'):
            return default
        # Extract digits from strings like "cited by 45" or "45 citations"
        import re
        numbers = re.findall(r'\d+', value)
        if numbers:
            return int(numbers[0])
    try:
        return int(float(value))
    except (ValueError, TypeError):
        return default

# ================================================================================
# SESSION STATE INITIALIZATION
# ================================================================================

def initialize_session_state():
    """Initialize all session state variables"""
    if 'step' not in st.session_state:
        st.session_state.step = 'input'

    if 'form_data' not in st.session_state:
        st.session_state.form_data = {
            'topic': '',
            'subject': '',
            'researcher': '',
            'institution': '',
            'date': datetime.now().strftime('%Y-%m-%d'),
            'citation_style': 'IEEE'
        }

    # API Keys (session-only)
    if 'api_keys' not in st.session_state:
        st.session_state.api_keys = {
            's2': '',
            'serp': '',
            'core': '',
            'scopus': '',
            'springer': '',
            'email': 'researcher@example.com'
        }

    if 'progress' not in st.session_state:
        st.session_state.progress = {'stage': '', 'detail': '', 'percent': 0}

    if 'research' not in st.session_state:
        st.session_state.research = {
            'queries': [],
            'sources': [],           # Now populated from ResearchOrchestrator
            'raw_results': [],       # Raw output from orchestrator
            'rejected_sources': [],
            'subtopics': [],
            'phrase_variations': [],
            'gaps': None             # Research gaps from orchestrator
        }

    if 'draft' not in st.session_state:
        st.session_state.draft = None

    if 'critique' not in st.session_state:
        st.session_state.critique = None

    if 'final_report' not in st.session_state:
        st.session_state.final_report = None

    if 'is_processing' not in st.session_state:
        st.session_state.is_processing = False

    if 'api_call_count' not in st.session_state:
        st.session_state.api_call_count = 0

    if 'last_api_call_time' not in st.session_state:
        st.session_state.last_api_call_time = 0

    if 'start_time' not in st.session_state:
        st.session_state.start_time = None

    if 'execution_time' not in st.session_state:
        st.session_state.execution_time = None

    if 'orchestrator' not in st.session_state:
        st.session_state.orchestrator = None

initialize_session_state()

# API key validation for Anthropic (for report generation)
try:
    ANTHROPIC_API_KEY = st.secrets["ANTHROPIC_API_KEY"]
    API_AVAILABLE = True
except:
    st.sidebar.error("‚ö†Ô∏è Anthropic API key not found in secrets (needed for report generation)")
    API_AVAILABLE = False


# ================================================================================
# UTILITY FUNCTIONS
# ================================================================================

def update_progress(stage: str, detail: str, percent: int):
    """Update progress bar and status"""
    st.session_state.progress = {
        'stage': stage, 
        'detail': detail, 
        'percent': min(100, percent)
    }


def generate_phrase_variations(topic: str) -> List[str]:
    """Generate phrase variations to avoid repetition"""
    return [
        topic,
        f"the field of {topic}",
        f"{topic} research",
        f"this domain",
        f"this research area",
        f"the {topic} field"
    ]


def parse_json_response(text: str) -> Dict:
    """Extract JSON from API response text"""
    try:
        cleaned = re.sub(r'```json\n?|```\n?', '', text).strip()
        return json.loads(cleaned)
    except:
        json_match = re.search(r'\{.*\}', text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass
        return {}


# ================================================================================
# API COMMUNICATION (For Report Generation Only)
# ================================================================================

def rate_limit_wait():
    """Rate limiting for Anthropic API calls"""
    current_time = time.time()
    time_since_last = current_time - st.session_state.last_api_call_time

    if time_since_last < MIN_API_DELAY:
        time.sleep(MIN_API_DELAY - time_since_last)

    st.session_state.last_api_call_time = time.time()
    st.session_state.api_call_count += 1


def call_anthropic_api(messages: List[Dict], max_tokens: int = 1000, use_fallback: bool = False) -> Dict:
    """Call Anthropic API for report generation with fallback model support"""
    if not API_AVAILABLE:
        raise Exception("Anthropic API key not configured")

    rate_limit_wait()

    headers = {
        "Content-Type": "application/json",
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": "2023-06-01"
    }

    model = MODEL_FALLBACK if use_fallback else MODEL_PRIMARY

    data = {
        "model": model,
        "max_tokens": max_tokens,
        "messages": messages
    }

    for attempt in range(3):
        try:
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=data,
                timeout=180  # Increased from 120
            )

            if response.status_code == 429:
                wait_time = RETRY_DELAYS[attempt]
                st.warning(f"‚è≥ Rate limited. Waiting {wait_time}s (attempt {attempt+1}/3)")
                time.sleep(wait_time)
                continue

            if response.status_code == 529:  # Overloaded
                wait_time = RETRY_DELAYS[attempt]
                st.warning(f"‚è≥ API overloaded. Waiting {wait_time}s (attempt {attempt+1}/3)")
                time.sleep(wait_time)
                continue

            response.raise_for_status()
            return response.json()

        except requests.exceptions.RequestException as e:
            st.warning(f"‚ö†Ô∏è API error (attempt {attempt+1}/3): {str(e)[:50]}")
            if attempt == 2:
                # Try fallback model before giving up
                if not use_fallback:
                    st.info("üîÑ Trying fallback model...")
                    return call_anthropic_api(messages, max_tokens, use_fallback=True)
                raise
            time.sleep(RETRY_DELAYS[attempt])

    # Try fallback model before giving up
    if not use_fallback:
        st.info("üîÑ Primary model failed. Trying fallback model...")
        return call_anthropic_api(messages, max_tokens, use_fallback=True)

    raise Exception("API call failed after 3 retries with both models")


# ================================================================================
# CORE INTEGRATION: Orchestrator Results ‚Üí Source Format
# ================================================================================

def convert_orchestrator_to_source_format(papers: List[Dict]) -> List[Dict]:
    """
    Convert ResearchOrchestrator output to streamlit_app_2 source format.

    ResearchOrchestrator returns papers with:
        - ieee_authors, title, venue, year, citations, doi, url, abstract, etc.

    streamlit_app_2 expects sources with:
        - title, url, content, metadata {authors, title, venue, year}

    This function bridges the two formats.
    """
    sources = []

    for paper in papers:
        # Create metadata dict from orchestrator fields
        metadata = {
            'authors': paper.get('ieee_authors', 'Unknown Authors'),
            'title': paper.get('title', 'Untitled'),
            'venue': paper.get('venue', 'Unknown Venue'),
            'year': str(paper.get('year', 'n.d.')),
            'citations': paper.get('citations', 0),
            'doi': paper.get('doi', 'N/A')
        }

        # Create source dict in streamlit_app_2 format
        source = {
            'title': paper.get('title', 'Untitled'),
            'url': paper.get('url', ''),
            'content': paper.get('abstract', paper.get('tldr', ''))[:500],
            'metadata': metadata,
            'credibilityScore': min(100, 50 + safe_int(paper.get('citations', 0)) // 10),
            'credibilityJustification': f"Found in {safe_int(paper.get('source_count', 1), 1)} database(s), {paper.get('citations', 0)} citations",
            'dateAccessed': datetime.now().isoformat(),
            # Keep original orchestrator data for reference
            '_orchestrator_data': paper
        }

        sources.append(source)

    return sources


# ================================================================================
# RESEARCH PIPELINE - Using ResearchOrchestrator
# ================================================================================

def execute_academic_research(topic: str, subject: str, api_keys: Dict, config: Dict) -> Tuple[List[Dict], Dict]:
    """
    Execute academic research using ResearchOrchestrator.

    Returns:
        (sources, gap_data) - Converted sources and research gap analysis
    """
    update_progress('Research', 'Initializing academic search engines...', 15)

    # Build search query from topic and subject
    search_query = f"{topic} {subject}".strip()

    # Configure ResearchOrchestrator
    orchestrator_config = {
        'abstract_limit': config.get('abstract_limit', 10),
        'high_consensus_threshold': config.get('high_consensus_threshold', 4),
        'citation_weight': config.get('citation_weight', 1.5),
        'source_weight': config.get('source_weight', 100),
        'enable_alerts': True,
        'enable_visualization': False,  # We'll handle our own viz
        'export_formats': ['csv', 'json'],
        'recency_boost': config.get('recency_boost', True),
        'recency_years': config.get('recency_years', 5),
        'recency_multiplier': config.get('recency_multiplier', 1.2)
    }

    # Set API keys in environment for orchestrator
    for key, value in api_keys.items():
        if key != 'email' and value:
            os.environ[f"{key.upper()}_API_KEY"] = value
        elif key == 'email' and value:
            os.environ['USER_EMAIL'] = value

    # Initialize orchestrator
    orchestrator = ResearchOrchestrator(config=orchestrator_config)
    st.session_state.orchestrator = orchestrator

    update_progress('Research', f'Searching 18 academic databases for "{search_query}"...', 25)

    # Execute search
    limit_per_engine = config.get('limit_per_engine', 15)
    results = orchestrator.run_search(search_query, limit_per_engine=limit_per_engine)

    if not results:
        raise Exception("No results found from academic databases")

    update_progress('Research', f'Found {len(results)} papers, analyzing research gaps...', 50)

    # Get research gaps (orchestrator saves this to file, we need to read it)
    gap_data = {
        'total_gaps_found': 0,
        'papers_analyzed': len(results),
        'gap_list': [],
        'top_keywords': []
    }

    # Try to read gap analysis if available
    try:
        gap_file = os.path.join(orchestrator.output_dir, "RESEARCH_GAPS.txt")
        if os.path.exists(gap_file):
            with open(gap_file, 'r', encoding='utf-8') as f:
                gap_content = f.read()
                # Parse gap data (simplified)
                gap_data['content'] = gap_content
    except:
        pass

    update_progress('Research', 'Converting results to report format...', 60)

    # Convert orchestrator results to source format
    sources = convert_orchestrator_to_source_format(results)

    update_progress('Research', f'Research complete! {len(sources)} sources ready.', 65)

    return sources, gap_data


def analyze_topic_with_ai(topic: str, subject: str) -> Dict:
    """
    Analyze topic and generate research plan.
    Now uses academic sources instead of web search.
    """
    update_progress('Topic Analysis', 'Creating research plan...', 10)

    variations = generate_phrase_variations(topic)
    st.session_state.research['phrase_variations'] = variations

    prompt = f"""Research plan for "{topic}" in {subject}.

Create:
1. 5 specific subtopics about "{topic}"
2. 5 academic search queries for finding papers (2020-2025)

Target databases: arXiv, IEEE, ACM, PubMed, Semantic Scholar

Return ONLY JSON:
{{
  "subtopics": ["aspect 1", "aspect 2", ...],
  "researchQueries": ["query 1", "query 2", ...]
}}"""

    try:
        response = call_anthropic_api(
            [{"role": "user", "content": prompt}], 
            max_tokens=800
        )
        text = "".join([c['text'] for c in response['content'] if c['type'] == 'text'])
        result = parse_json_response(text)

        if result.get('subtopics') and result.get('researchQueries'):
            return result
    except:
        pass

    # Fallback
    return {
        "subtopics": [
            f"Foundations of {topic}",
            f"Recent Advances in {topic}",
            f"Applications of {topic}",
            f"Challenges in {topic}",
            f"Future of {topic}"
        ],
        "researchQueries": [
            f"{topic} research 2024",
            f"{topic} academic papers",
            f"{topic} recent developments",
            f"{topic} applications",
            f"{topic} future trends"
        ]
    }


# ================================================================================
# CITATION MODULE (Unchanged - works with proper data)
# ================================================================================

def format_authors_ieee(authors_str: str) -> str:
    """Format multiple authors for IEEE style"""
    if not authors_str:
        return "Research Team"

    if 'et al' in authors_str.lower():
        return authors_str

    # Split by comma or "and"
    authors = re.split(r',\s*|\s+and\s+', authors_str)
    authors = [a.strip() for a in authors if a.strip()]

    if not authors:
        return "Research Team"

    if len(authors) == 1:
        return authors[0]
    elif len(authors) == 2:
        return f"{authors[0]} and {authors[1]}"
    else:
        return ', '.join(authors[:-1]) + ', and ' + authors[-1]


def format_citation_ieee(source: Dict, index: int) -> str:
    """Format citation in IEEE style"""
    meta = source.get('metadata', {})
    authors = meta.get('authors', 'Research Team')
    title = meta.get('title', 'Research Article')
    venue = meta.get('venue', 'Academic Publication')
    year = meta.get('year', '2024')
    url = source.get('url', '')

    if not authors or authors.lower() in ['unknown', 'author unknown']:
        authors = venue + ' Authors'

    if not title or title.lower() == 'unknown':
        title = 'Research Article'

    formatted_authors = format_authors_ieee(authors)
    citation = f'[{index}] {formatted_authors}, "{title}," {venue}, {year}. \nLink: {url}'

    return citation


def format_citation_apa(source: Dict, index: int) -> str:
    """Format citation in APA style"""
    meta = source.get('metadata', {})
    authors = meta.get('authors', 'Research Team')
    title = meta.get('title', 'Research Article')
    venue = meta.get('venue', 'Academic Publication')
    year = meta.get('year', '2024')
    url = source.get('url', '')

    if not authors or authors.lower() in ['unknown', 'author unknown']:
        authors = venue + ' Authors'

    if not title or title.lower() == 'unknown':
        title = 'Research Article'

    citation = f"{authors} ({year}). {title}. <i>{venue}</i>. Retrieved from <a href=\"{url}\" target=\"_blank\">{url}</a>"

    return citation


# ================================================================================
# DRAFT GENERATION (Modified to use academic sources)
# ================================================================================

def generate_draft_optimized(
    topic: str, 
    subject: str, 
    subtopics: List[str], 
    sources: List[Dict], 
    variations: List[str]
) -> Dict:
    """Generate report draft using academic sources"""
    update_progress('Drafting', 'Writing report...', 70)

    if not sources:
        raise Exception("No sources available")

    # Prepare source list for prompt (top 12 sources)
    source_list = []
    for i, s in enumerate(sources[:12], 1):
        meta = s.get('metadata', {})
        source_list.append(f"""[{i}] {meta.get('title', 'Unknown')} ({meta.get('year', 'N/A')})
Authors: {meta.get('authors', 'Unknown')}
Venue: {meta.get('venue', 'Unknown')}
{s['url'][:70]}
Abstract: {s.get('content', '')[:300]}""")

    sources_text = "\n\n".join(source_list)

    # Phrase variation instruction
    variations_text = f"""CRITICAL INSTRUCTION - PHRASE VARIATION:
You MUST use these variations to avoid repetition:
- "{topic}" - USE THIS SPARINGLY (maximum 5 times)
- "{variations[1]}" - PREFER THIS
- "{variations[2]}" - USE THIS OFTEN
- "this domain" - USE THIS
- "this research area" - USE THIS

DO NOT repeat "{topic}" more than 5 times total."""

    prompt = f"""Write academic report about "{topic}" in {subject}.

{variations_text}

REQUIREMENTS:
- Use ONLY provided academic sources below
- Cite sources as [1], [2], [3] etc. - just the number in brackets
- Include specific data, statistics, and years from sources
- VARY your phrasing - avoid repetition

SUBTOPICS: {', '.join(subtopics)}

ACADEMIC SOURCES:
{sources_text}

Write these sections:
1. Abstract (150-250 words)
2. Introduction
3. Literature Review
4. 3-4 Main Sections covering subtopics
5. Data & Analysis
6. Challenges
7. Future Outlook
8. Conclusion

Return ONLY valid JSON:
{{
  "abstract": "...",
  "introduction": "...",
  "literatureReview": "...",
  "mainSections": [{{"title": "...", "content": "..."}}],
  "dataAnalysis": "...",
  "challenges": "...",
  "futureOutlook": "...",
  "conclusion": "..."
}}"""

    response = call_anthropic_api(
        [{"role": "user", "content": prompt}],
        max_tokens=6000
    )
    text = "".join([c['text'] for c in response['content'] if c['type'] == 'text'])
    draft = parse_json_response(text)

    # Ensure all required keys exist
    required_keys = [
        'abstract', 'introduction', 'literatureReview', 'mainSections',
        'dataAnalysis', 'challenges', 'futureOutlook', 'conclusion'
    ]

    for key in required_keys:
        if key not in draft or not draft[key]:
            if key == 'mainSections':
                draft[key] = [{'title': 'Analysis', 'content': 'Content.'}]
            else:
                draft[key] = f"Section about the topic."

    # Fix citations
    def fix_citations(text):
        if isinstance(text, str):
            text = re.sub(r'\[Source\s+(\d+)\]', r'[\1]', text, flags=re.IGNORECASE)
            text = re.sub(r'\[source\s+(\d+)\]', r'[\1]', text, flags=re.IGNORECASE)
        return text

    for key in draft:
        if isinstance(draft[key], str):
            draft[key] = fix_citations(draft[key])
        elif isinstance(draft[key], list):
            for i, item in enumerate(draft[key]):
                if isinstance(item, dict):
                    for k, v in item.items():
                        if isinstance(v, str):
                            item[k] = fix_citations(v)
                elif isinstance(item, str):
                    draft[key][i] = fix_citations(item)

    return draft


def critique_draft_simple(draft: Dict, sources: List[Dict]) -> Dict:
    """Quality check"""
    update_progress('Review', 'Quality check...', 85)

    draft_text = json.dumps(draft).lower()
    citation_count = len(re.findall(r'\[\d+\]', draft_text))

    return {
        'topicRelevance': 85,
        'citationQuality': min(95, 70 + citation_count * 2),
        'overallScore': 85,
        'recommendations': ['Report generated with academic sources']
    }


def refine_draft_simple(draft: Dict, topic: str, sources_count: int) -> Dict:
    """Add executive summary"""
    update_progress('Refinement', 'Final polish...', 92)

    draft['executiveSummary'] = (
        f"This comprehensive report examines {topic}, analyzing key developments, "
        f"challenges, and future directions based on {sources_count} authoritative academic sources."
    )

    return draft


# ================================================================================
# HTML GENERATION (Unchanged)
# ================================================================================

def generate_html_report_optimized(
    refined_draft: Dict, 
    form_data: Dict, 
    sources: List[Dict]
) -> str:
    """Generate HTML report"""
    update_progress('Generating HTML', 'Creating document...', 97)

    try:
        report_date = datetime.strptime(
            form_data['date'], 
            '%Y-%m-%d'
        ).strftime('%B %d, %Y')
    except:
        report_date = datetime.now().strftime('%B %d, %Y')

    style = form_data.get('citation_style', 'IEEE')

    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{form_data['topic']} - Research Report</title>
    <style>
        @page {{ margin: 1in; }}
        body {{
            font-family: 'Times New Roman', serif;
            font-size: 12pt;
            line-height: 1.6;
            color: #000;
            max-width: 8.5in;
            margin: 0 auto;
            padding: 0.5in;
        }}
        .cover {{
            text-align: center;
            padding-top: 2in;
            page-break-after: always;
        }}
        .cover h1 {{
            font-size: 24pt;
            font-weight: bold;
            margin: 1in 0 0.5in 0;
        }}
        .cover .meta {{
            font-size: 14pt;
            margin: 0.25in 0;
        }}
        h1 {{
            font-size: 18pt;
            margin-top: 0.5in;
            border-bottom: 2px solid #333;
            padding-bottom: 0.1in;
        }}
        h2 {{
            font-size: 14pt;
            margin-top: 0.3in;
            font-weight: bold;
        }}
        p {{
            text-align: justify;
            margin: 0.15in 0;
        }}
        .abstract {{
            font-style: italic;
            margin: 0.25in 0.5in;
        }}
        .references {{
            page-break-before: always;
        }}
        .ref-item {{
            margin: 0.15in 0 0.15in 0.5in;
            text-indent: -0.5in;
            padding-left: 0.5in;
            font-size: 10pt;
            line-height: 1.4;
        }}
        .ref-item a {{
            color: #0066CC;
            text-decoration: none;
        }}
        .ref-item a:hover {{
            text-decoration: underline;
        }}
    </style>
</head>
<body>
    <div class="cover">
        <h1>{form_data['topic']}</h1>
        <div class="meta">Research Report</div>
        <div class="meta">Subject: {form_data['subject']}</div>
        <div class="meta" style="margin-top: 1in;">
            {form_data['researcher']}<br>
            {form_data['institution']}<br>
            {report_date}
        </div>
        <div class="meta" style="margin-top: 0.5in; font-size: 10pt;">
            {style} Citation Format
        </div>
    </div>

    <h1>Executive Summary</h1>
    <p>{refined_draft.get('executiveSummary', '')}</p>

    <h1>Abstract</h1>
    <div class="abstract">{refined_draft.get('abstract', '')}</div>

    <h1>Introduction</h1>
    <p>{refined_draft.get('introduction', '')}</p>

    <h1>Literature Review</h1>
    <p>{refined_draft.get('literatureReview', '')}</p>
"""

    for section in refined_draft.get('mainSections', []):
        html += f"""
    <h2>{section.get('title', 'Section')}</h2>
    <p>{section.get('content', '')}</p>
"""

    html += f"""
    <h1>Data & Analysis</h1>
    <p>{refined_draft.get('dataAnalysis', '')}</p>

    <h1>Challenges</h1>
    <p>{refined_draft.get('challenges', '')}</p>

    <h1>Future Outlook</h1>
    <p>{refined_draft.get('futureOutlook', '')}</p>

    <h1>Conclusion</h1>
    <p>{refined_draft.get('conclusion', '')}</p>

    <div class="references">
        <h1>References</h1>
"""

    for i, source in enumerate(sources, 1):
        if style == 'APA':
            citation = format_citation_apa(source, i)
        else:
            citation = format_citation_ieee(source, i)
        html += f'        <div class="ref-item">{citation}</div>\n'

    html += """
    </div>
</body>
</html>"""

    return html


# ================================================================================
# MAIN EXECUTION PIPELINE
# ================================================================================

def execute_research_pipeline():
    """Execute complete research and report generation pipeline"""
    st.session_state.is_processing = True
    st.session_state.step = 'processing'
    st.session_state.api_call_count = 0
    st.session_state.start_time = time.time()

    try:
        if not API_AVAILABLE:
            raise Exception("Anthropic API key not configured (needed for report generation)")

        if not ORCHESTRATOR_AVAILABLE:
            raise Exception("master_orchestrator not available")

        topic = st.session_state.form_data['topic']
        subject = st.session_state.form_data['subject']
        api_keys = st.session_state.api_keys

        # Configuration for orchestrator
        orchestrator_config = {
            'limit_per_engine': st.session_state.get('limit_per_engine', 15),
            'abstract_limit': st.session_state.get('abstract_limit', 10),
            'high_consensus_threshold': st.session_state.get('high_consensus_threshold', 4),
            'citation_weight': st.session_state.get('citation_weight', 1.5),
            'source_weight': st.session_state.get('source_weight', 100),
            'recency_boost': st.session_state.get('recency_boost', True),
            'recency_years': st.session_state.get('recency_years', 5),
            'recency_multiplier': st.session_state.get('recency_multiplier', 1.2)
        }

        # Stage 1: Topic Analysis
        st.info("üîç Stage 1/5: Analyzing topic...")
        analysis = analyze_topic_with_ai(topic, subject)
        st.session_state.research.update({
            'subtopics': analysis['subtopics'],
            'queries': analysis['researchQueries']
        })

        # Stage 2: Academic Research (Using ResearchOrchestrator)
        st.info("üî¨ Stage 2/5: Searching academic databases...")
        sources, gap_data = execute_academic_research(
            topic, 
            subject, 
            api_keys,
            orchestrator_config
        )
        st.session_state.research.update({
            'sources': sources,
            'gaps': gap_data
        })

        if len(sources) < 3:
            raise Exception(f"Only {len(sources)} sources found. Need at least 3.")

        # Stage 3: Draft Generation
        st.info("‚úçÔ∏è Stage 3/5: Writing report...")
        draft = generate_draft_optimized(
            topic, 
            subject, 
            analysis['subtopics'],
            sources, 
            st.session_state.research['phrase_variations']
        )
        st.session_state.draft = draft

        # Stage 4: Quality Check
        st.info("üîç Stage 4/5: Quality check...")
        critique = critique_draft_simple(draft, sources)
        st.session_state.critique = critique

        # Stage 5: Refinement & HTML Generation
        st.info("‚ú® Stage 5/5: Final refinement...")
        refined = refine_draft_simple(draft, topic, len(sources))
        st.session_state.final_report = refined

        html = generate_html_report_optimized(
            refined, 
            st.session_state.form_data, 
            sources
        )
        st.session_state.html_report = html

        st.session_state.execution_time = time.time() - st.session_state.start_time

        update_progress("Complete", "Report generated successfully!", 100)
        st.session_state.step = 'complete'

        exec_mins = int(st.session_state.execution_time // 60)
        exec_secs = int(st.session_state.execution_time % 60)
        st.success(
            f"‚úÖ Complete in {exec_mins}m {exec_secs}s! "
            f"{len(sources)} academic sources, {st.session_state.api_call_count} API calls"
        )

    except Exception as e:
        st.session_state.execution_time = time.time() - st.session_state.start_time if st.session_state.start_time else 0
        update_progress("Error", str(e), 0)
        st.session_state.step = 'error'
        st.error(f"‚ùå Error: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
    finally:
        st.session_state.is_processing = False


def reset_system():
    """Reset system"""
    for key in list(st.session_state.keys()):
        if key not in ['form_data', 'api_keys']:
            del st.session_state[key]
    st.session_state.step = 'input'
    st.session_state.api_call_count = 0
    st.session_state.start_time = None
    st.session_state.execution_time = None


# ================================================================================
# SIDEBAR - API CONFIGURATION
# ================================================================================

def render_sidebar():
    """Render sidebar with API configuration"""
    with st.sidebar:
        st.header("‚öôÔ∏è Configuration")

        # Academic Engine Configuration
        st.subheader("üîë Academic Database API Keys")
        st.info("Keys are session-only (lost on refresh)")

        with st.expander("Enter API Keys (Optional)", expanded=False):
            st.markdown("""
            **Free Engines (No Key Needed):**
            - arXiv, PubMed, OpenAlex, Crossref/DOI
            - Europe PMC, PLOS, SSRN, DeepDyve
            - Wiley, Taylor & Francis, ACM, DBLP, SAGE

            **Premium Engines (Key Required):**
            - Semantic Scholar (free key available)
            - Google Scholar (via SERP API)
            - CORE, SCOPUS, Springer Nature
            """)

            # API Key inputs
            s2_key = st.text_input(
                "Semantic Scholar API Key",
                value=st.session_state.api_keys.get('s2', ''),
                type="password",
                help="Get free key at semanticscholar.org/product/api"
            )

            serp_key = st.text_input(
                "SERP API Key (Google Scholar)",
                value=st.session_state.api_keys.get('serp', ''),
                type="password",
                help="Get key at serpapi.com"
            )

            core_key = st.text_input(
                "CORE API Key",
                value=st.session_state.api_keys.get('core', ''),
                type="password",
                help="Get key at core.ac.uk/services/api"
            )

            scopus_key = st.text_input(
                "SCOPUS API Key",
                value=st.session_state.api_keys.get('scopus', ''),
                type="password",
                help="Get key at dev.elsevier.com"
            )

            springer_key = st.text_input(
                "Springer Nature API Key",
                value=st.session_state.api_keys.get('springer', ''),
                type="password",
                help="Get key at dev.springernature.com"
            )

            email = st.text_input(
                "Your Email",
                value=st.session_state.api_keys.get('email', 'researcher@example.com'),
                help="Used for arXiv/PubMed API requests"
            )

            if st.button("‚úÖ Apply Keys", use_container_width=True):
                st.session_state.api_keys = {
                    's2': s2_key.strip(),
                    'serp': serp_key.strip(),
                    'core': core_key.strip(),
                    'scopus': scopus_key.strip(),
                    'springer': springer_key.strip(),
                    'email': email.strip()
                }
                st.success("Keys applied!")
                st.rerun()

        # Search Parameters
        st.subheader("üîç Search Parameters")

        limit_per_engine = st.slider(
            "Results per engine",
            min_value=5,
            max_value=50,
            value=15,
            step=5
        )
        st.session_state['limit_per_engine'] = limit_per_engine

        abstract_limit = st.number_input(
            "Deep Look Limit",
            min_value=1,
            max_value=20,
            value=10
        )
        st.session_state['abstract_limit'] = abstract_limit

        # Advanced Settings
        with st.expander("Advanced Settings"):
            st.session_state['citation_weight'] = st.slider(
                "Citation Weight", 0.1, 5.0, 1.5, 0.1
            )
            st.session_state['source_weight'] = st.number_input(
                "Source Weight", 10, 500, 100, 10
            )
            st.session_state['high_consensus_threshold'] = st.number_input(
                "Consensus Threshold", 2, 7, 4
            )
            st.session_state['recency_boost'] = st.checkbox(
                "Recency Boost", value=True
            )
            st.session_state['recency_years'] = st.slider(
                "Recent Years", 1, 10, 5
            )

        st.divider()

        # Engine Status
        st.subheader("üìä Engine Status")

        # Count available engines
        free_engines = ["arXiv", "PubMed", "OpenAlex", "Crossref/DOI", 
                       "Europe PMC", "PLOS", "SSRN", "DeepDyve",
                       "Wiley", "Taylor & Francis", "ACM", "DBLP", "SAGE"]
        premium_engines = []

        if st.session_state.api_keys.get('s2'):
            premium_engines.append("Semantic Scholar")
        if st.session_state.api_keys.get('serp'):
            premium_engines.append("Google Scholar")
        if st.session_state.api_keys.get('core'):
            premium_engines.append("CORE")
        if st.session_state.api_keys.get('scopus'):
            premium_engines.append("SCOPUS")
        if st.session_state.api_keys.get('springer'):
            premium_engines.append("Springer Nature")

        st.markdown(f"**Free Engines:** {len(free_engines)} always available")
        for engine in free_engines[:5]:
            st.markdown(f"<span class='engine-badge'>‚úì {engine}</span>", unsafe_allow_html=True)

        if premium_engines:
            st.markdown(f"**Premium Engines:** {len(premium_engines)} active")
            for engine in premium_engines:
                st.markdown(f"<span class='engine-badge premium'>‚úì {engine}</span>", unsafe_allow_html=True)
        else:
            st.info("Add API keys to unlock 5 premium engines")


# ================================================================================
# MAIN UI
# ================================================================================

def main():
    st.title("üìù Academic Report Writer Pro")
    st.markdown("**Version 7.0 - Integrated with 18 Academic Search Engines**")

    # Render sidebar
    render_sidebar()

    # Check availability
    if not ORCHESTRATOR_AVAILABLE:
        st.error("‚ùå master_orchestrator not found. Please ensure master_orchestrator.py is in the same directory.")
        return

    if not API_AVAILABLE:
        st.warning("‚ö†Ô∏è Anthropic API key not configured. Report generation will not work.")

    # Main content based on step
    if st.session_state.step == 'input':
        render_input_screen()
    elif st.session_state.step == 'processing':
        render_processing_screen()
    elif st.session_state.step == 'complete':
        render_complete_screen()
    elif st.session_state.step == 'error':
        render_error_screen()


def render_input_screen():
    """Render input form"""
    st.markdown("### Report Configuration")

    col1, col2 = st.columns(2)
    with col1:
        topic = st.text_input(
            "Topic *", 
            value=st.session_state.form_data['topic'], 
            placeholder="e.g., Quantum Computing in Drug Discovery"
        )
        subject = st.text_input(
            "Subject *", 
            value=st.session_state.form_data['subject'],
            placeholder="e.g., Computer Science"
        )
    with col2:
        researcher = st.text_input(
            "Researcher *", 
            value=st.session_state.form_data['researcher'],
            placeholder="Your name"
        )
        institution = st.text_input(
            "Institution *", 
            value=st.session_state.form_data['institution'],
            placeholder="University/Organization"
        )

    col3, col4 = st.columns(2)
    with col3:
        date = st.date_input(
            "Date", 
            value=datetime.strptime(st.session_state.form_data['date'], '%Y-%m-%d')
        )
    with col4:
        style = st.selectbox("Citation Style", ["IEEE", "APA"])

    # Update form data
    st.session_state.form_data.update({
        'topic': topic, 
        'subject': subject, 
        'researcher': researcher,
        'institution': institution, 
        'date': date.strftime('%Y-%m-%d'),
        'citation_style': style
    })

    valid = all([topic, subject, researcher, institution])

    st.markdown("---")

    # Info box
    st.info("""
    **How it works:**
    1. üîç Searches 18 academic databases (arXiv, IEEE, PubMed, Semantic Scholar, etc.)
    2. üìö Extracts real metadata (authors, venues, years) from academic APIs
    3. ‚úçÔ∏è Generates report with proper IEEE/APA citations
    4. üîó Includes clickable links to papers

    **Time:** 3-5 minutes | **Sources:** Real academic papers with verified metadata
    """)

    if st.button(
        "üöÄ Generate Report", 
        disabled=not valid or not API_AVAILABLE, 
        type="primary", 
        use_container_width=True
    ):
        execute_research_pipeline()
        st.rerun()

    if not valid:
        st.warning("‚ö†Ô∏è Please fill all required fields")


def render_processing_screen():
    """Render processing screen"""
    st.markdown("### üîÑ Processing")

    col1, col2 = st.columns([4, 1])
    with col1:
        st.markdown(f"**{st.session_state.progress['stage']}**")
        st.progress(st.session_state.progress['percent'] / 100)
    with col2:
        st.metric("Progress", f"{st.session_state.progress['percent']}%")

    st.info(st.session_state.progress['detail'])

    if st.session_state.start_time:
        elapsed = time.time() - st.session_state.start_time
        elapsed_mins = int(elapsed // 60)
        elapsed_secs = int(elapsed % 60)
        st.caption(
            f"‚è±Ô∏è Elapsed: {elapsed_mins}m {elapsed_secs}s | "
            f"API Calls: {st.session_state.api_call_count}"
        )

    # Show sources as they're found
    if st.session_state.research['sources']:
        with st.expander(
            f"üìö Academic Sources Found ({len(st.session_state.research['sources'])})", 
            expanded=True
        ):
            for i, s in enumerate(st.session_state.research['sources'][:10], 1):
                meta = s.get('metadata', {})
                st.markdown(
                    f"**{i}.** {meta.get('title', 'Unknown')[:80]}...  "
                    f"üë§ {meta.get('authors', 'Unknown')} | "
                    f"üìä {s.get('credibilityScore', 0)}%"
                )

    if st.session_state.is_processing:
        time.sleep(3)
        st.rerun()


def render_complete_screen():
    """Render completion screen"""
    st.success("‚úÖ Report Generated Successfully!")

    if st.session_state.execution_time:
        exec_mins = int(st.session_state.execution_time // 60)
        exec_secs = int(st.session_state.execution_time % 60)
        st.info(f"‚è±Ô∏è **Execution Time:** {exec_mins} minutes {exec_secs} seconds")

    # Metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Academic Sources", len(st.session_state.research['sources']))
    with col2:
        high_consensus = sum(1 for s in st.session_state.research['sources'] 
                           if s.get('_orchestrator_data', {}).get('source_count', 1) >= 4)
        st.metric("High Consensus", high_consensus)
    with col3:
        avg_cites = sum(s.get('_orchestrator_data', {}).get('citations_int', 0) 
                       for s in st.session_state.research['sources']) / len(st.session_state.research['sources'])                        if st.session_state.research['sources'] else 0
        st.metric("Avg Citations", f"{avg_cites:.1f}")
    with col4:
        st.metric("Anthropic API Calls", st.session_state.api_call_count)

    st.markdown("---")

    # Download
    col1, col2 = st.columns(2)
    with col1:
        if 'html_report' in st.session_state:
            filename = f"{st.session_state.form_data['topic'].replace(' ', '_')}_Report.html"
            st.download_button(
                "üì• Download HTML Report",
                data=st.session_state.html_report,
                file_name=filename,
                mime="text/html",
                type="primary",
                use_container_width=True
            )
            st.info("""
            **To create PDF:**
            1. Open HTML in browser
            2. Press Ctrl+P (Cmd+P on Mac)
            3. Select "Save as PDF"
            """)

    with col2:
        st.metric("File Size", f"{len(st.session_state.html_report) / 1024:.1f} KB")
        st.metric("Quality Score", f"{st.session_state.critique.get('overallScore', 0)}/100")

    # Research gaps
    if st.session_state.research.get('gaps'):
        with st.expander("üîç Research Gaps Identified"):
            gaps = st.session_state.research['gaps']
            st.markdown(f"**Total Gaps Found:** {gaps.get('total_gaps_found', 0)}")
            st.markdown(f"**Papers Analyzed:** {gaps.get('papers_analyzed', 0)}")
            if 'content' in gaps:
                st.text_area("Gap Analysis", gaps['content'], height=200)

    st.markdown("---")

    # Sources preview
    with st.expander("üìö References Preview", expanded=False):
        for i, s in enumerate(st.session_state.research['sources'][:20], 1):
            meta = s.get('metadata', {})
            orch = s.get('_orchestrator_data', {})

            st.markdown(f"**[{i}]** {meta.get('title', 'N/A')}")
            st.caption(f"üë§ {meta.get('authors', 'N/A')} | üìÖ {meta.get('year', 'N/A')} | üìñ {meta.get('venue', 'N/A')}")
            st.caption(f"üîó [{s['url']}]({s['url']})")
            if orch.get('source_count'):
                st.caption(f"‚úì Found in {orch['source_count']} database(s) | üìä {orch.get('citations', 0)} citations")
            st.divider()

    if st.button("üîÑ Generate Another Report", type="secondary", use_container_width=True):
        reset_system()
        st.rerun()


def render_error_screen():
    """Render error screen"""
    st.error("‚ùå Error Occurred")
    st.warning(st.session_state.progress['detail'])

    if st.session_state.execution_time:
        exec_mins = int(st.session_state.execution_time // 60)
        exec_secs = int(st.session_state.execution_time % 60)
        st.caption(f"Failed after {exec_mins}m {exec_secs}s")

    if st.button("üîÑ Try Again", type="primary", use_container_width=True):
        reset_system()
        st.rerun()


# ================================================================================
# FOOTER
# ================================================================================

st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; font-size: 0.85em;">
    <strong>Version 7.0 - Integrated with ResearchOrchestrator</strong><br>
    üî¨ 18 Academic Engines ‚Ä¢ üìö Real Metadata ‚Ä¢ ‚úÖ Proper Citations ‚Ä¢ üîó Clickable URLs
</div>
""", unsafe_allow_html=True)


if __name__ == "__main__":
    main()
